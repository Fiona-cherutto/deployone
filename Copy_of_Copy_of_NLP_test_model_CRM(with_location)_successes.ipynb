{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of NLP  test model CRM(with location) successes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fiona-cherutto/deployone/blob/main/Copy_of_Copy_of_NLP_test_model_CRM(with_location)_successes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCyWLghYwld7",
        "outputId": "1c3cd363-936a-40ab-d8be-1ad80a9f13d8"
      },
      "source": [
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import string\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from scipy.sparse import csr_matrix\r\n",
        "import xlrd\r\n",
        "import nltk\r\n",
        "!pip install nltk==3.5\r\n",
        "!pip install regex==2020.6.8\r\n",
        "!pip install joblib==0.16.0\r\n",
        "!pip install tqdm==4.47.0\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.6/dist-packages (3.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk==3.5) (2020.6.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk==3.5) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk==3.5) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk==3.5) (4.47.0)\n",
            "Requirement already satisfied: regex==2020.6.8 in /usr/local/lib/python3.6/dist-packages (2020.6.8)\n",
            "Requirement already satisfied: joblib==0.16.0 in /usr/local/lib/python3.6/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm==4.47.0 in /usr/local/lib/python3.6/dist-packages (4.47.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoMZm4bAwvPa"
      },
      "source": [
        "df =  pd.read_excel('/content/1000 leads.xlsx')\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khwVVqU7xCwy",
        "outputId": "619016c1-dc72-4c56-c7e0-135cbb7bf060"
      },
      "source": [
        "pd.set_option('display.max_rows', None)\r\n",
        "pd.set_option('display.max_columns', None)\r\n",
        "pd.set_option('display.width', None)\r\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPoiCjqDDtMH"
      },
      "source": [
        "df = df.rename(columns={'Status information':'Status_information','Status ':'Status'})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6vAU1MCDvQr"
      },
      "source": [
        "df[\"Location\"] = df[\"Location\"].str.lower()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDYJUWg5z8Tr"
      },
      "source": [
        "pattern = r\"\\d*\\/\\d*\\/[a-zA-z]*:|\\d*\\/\\d*\\/\\d*\\(\\w*\\):|\\d*\\|\\w*\\|\\w*:|\\(\\w*\\):|\\d*\\-\\d*\\-\\d*\\(\\w*\\):|\\d*\\/\\d*\\w*:|\\d*\\/\\w*:|\\d*\\/\\d*\\/\\w*\\|:|\\d*\\/\\d*\\ *\\(\\w*\\)|\\d*\\ *\\w*\\ *\\|\\ *\\w*\\ *:|\\d*\\/\\d*\\/\\d*\\(\\w*:|\\d*\\/\\w*\\/\\w*|\\d*\\/\\d*\\/\\d*\\|\\(\\w*\\)|\\(\\w*\\)|\\d*\\-\\d*\\-\\d*|^\\ *|^\\:\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J82LGzkA0Jub"
      },
      "source": [
        "df[\"Status_information\"] = df[\"Status_information\"].apply(lambda x: re.sub(pattern,\" \",str(x)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5s96ZNB1X2K"
      },
      "source": [
        "del df['Unnamed: 4']\r\n",
        "del df[\"Lead Name\"]\r\n",
        "del df[\"Location\"]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk_FNmAR1cXy"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH0H93Y0I8hi"
      },
      "source": [
        "df['Status'] = df['Status'].str.lower()\r\n",
        "df['Status'] = df[\"Status\"].replace(' ','')\r\n",
        "\r\n",
        "df['Status'] = df[\"Status\"].str.replace('conveted','converted')\r\n",
        "\r\n",
        "df['Status'] = df[\"Status\"].str.replace('converted ','converted')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUvgT5xNwZV8"
      },
      "source": [
        "from sklearn.utils import resample\r\n",
        "# Separate majority and minority classes\r\n",
        "df_majority = df[df['Status'] == 'not converted']\r\n",
        "df_minority = df[df['Status'] == 'converted']\r\n",
        " \r\n",
        "# Upsample minority class\r\n",
        "df_minority_upsampled = resample(df_minority, \r\n",
        "                                 replace=True,     # sample with replacement\r\n",
        "                                 n_samples=len(df_majority),    # to match majority class\r\n",
        "                                 random_state=123) # random\r\n",
        " \r\n",
        "# Combine majority class with upsampled minority class\r\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjjgARElyLbP"
      },
      "source": [
        "def message_text_process(mess):\r\n",
        "  no_punctuation = [char for char in mess if char]\r\n",
        "  no_punctuation = \"\".join(no_punctuation)\r\n",
        "  return [word for word in no_punctuation.split() if word.lower()\r\n",
        "          not in stopwords.words(\"english\")]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDI3FSif0oW0"
      },
      "source": [
        "df_upsampled['Status_information'] = df_upsampled['Status_information'].apply(message_text_process).astype(str)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7GfywRhx92A"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer #bag of words\r\n",
        "#data = message_text_process(df_upsampled[\"Status_information\"])\r\n",
        "#count_vec = CountVectorizer(analyzer=message_text_process)\r\n",
        "count_vec = CountVectorizer()\r\n",
        "X = count_vec.fit_transform(df_upsampled[\"Status_information\"])\r\n",
        "#X = count_vec.fit_transform(df_upsampled[\"Status_information\"])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9jt-ZC9ySD-"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer #TF.IDF\r\n",
        "tfidf = TfidfTransformer()\r\n",
        "X = tfidf.fit_transform(X)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBDO-rdZk7py",
        "outputId": "c783126c-d0d9-48cd-ee8f-824ed2071068"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1734, 1245)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di7bb3hzdZC5",
        "outputId": "e1c784dc-f382-47de-e7f5-214293f4a6e6"
      },
      "source": [
        "X"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1734x1245 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 14330 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXwmdOvfkuz1",
        "outputId": "a59ef10e-07ea-47bc-b608-c08e32049040"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1734, 1245)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hplrK8rPkzM7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0nQhon2yawO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df_upsampled['Status'], test_size=0.2, random_state=42)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXEe2vSgygbz",
        "outputId": "5d850610-d1df-491e-e75a-9b76b21371c5"
      },
      "source": [
        "#random foresset classifier with TFIDF\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "Random_Forest_Classifier = RandomForestClassifier()\r\n",
        "forest = Random_Forest_Classifier.fit(X_train,y_train)\r\n",
        "predicted = forest.predict(X_test)\r\n",
        "expected = y_test\r\n",
        "print(metrics.classification_report(expected, predicted))\r\n",
        "print(metrics.confusion_matrix(expected, predicted))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "    converted       0.95      0.98      0.96       164\n",
            "not converted       0.98      0.95      0.96       183\n",
            "\n",
            "     accuracy                           0.96       347\n",
            "    macro avg       0.96      0.96      0.96       347\n",
            " weighted avg       0.96      0.96      0.96       347\n",
            "\n",
            "[[160   4]\n",
            " [  9 174]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSxNLdb4JvrY"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yeMlyl6JZzY"
      },
      "source": [
        "pickle_out = open('Random_Forest_Classifier.pkl', 'wb')\r\n",
        "pickle.dump(Random_Forest_Classifier, pickle_out)\r\n",
        "pickle_out.close()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTGPrecOJakG"
      },
      "source": [
        "pickle_out = open('tfidf_Transformer.pkl', 'wb')\r\n",
        "pickle.dump(tfidf, pickle_out)\r\n",
        "pickle_out.close()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHCMcDjsJbLn"
      },
      "source": [
        "pickle_out = open('count_vec.pkl', 'wb')\r\n",
        "pickle.dump(count_vec, pickle_out)\r\n",
        "pickle_out.close()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7sGyWDaygMH"
      },
      "source": [
        "def test_model():\r\n",
        "  test_text=input()\r\n",
        "  location_label = np.array(29).reshape(-1,1)\r\n",
        "\r\n",
        "  \r\n",
        "  bag_words_test = message_text_process(test_text)\r\n",
        "  # bag_words =  CountVectorizer(analyzer=message_text_process).fit(test_tex])\r\n",
        "  message_bagwords_test = count_vec.transform([test_text])\r\n",
        "  #tfid_transformer = TfidfTransformer().fit(message_bagwords)\r\n",
        "  message_tfidf = tfidf.transform(message_bagwords_test)\r\n",
        "  #message_tfidf = csr_matrix.toarray(message_tfidf)\r\n",
        "  #data = np.append(message_tfidf,location_label,axis=1)\r\n",
        "  \r\n",
        "  y_pred = Random_Forest_Classifier.predict(message_tfidf)\r\n",
        "\r\n",
        "  print(y_pred[0])\r\n",
        "  # print(location_label.shape)\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0ERUb7-zcO5",
        "outputId": "e677d46e-4685-4f3e-9fa7-9255497b3d6e"
      },
      "source": [
        "test_model()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " i am not interested\n",
            "not converted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "KAJw2Lt8DN0M",
        "outputId": "c3c10024-99a6-4c19-c57b-44a88a1b0be8"
      },
      "source": [
        "variable = \"hello i am interested\"\r\n",
        "\r\n",
        "# variable = np.array()\r\n",
        "# variable = np.append(variable)\r\n",
        "\r\n",
        "x = pd.DataFrame(variable)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-efe3c3d0aafb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# variable = np.append(variable)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w2oh5Z1yYsP6",
        "outputId": "3556b8b9-6a27-4e7a-8a89-e6d87d500be6"
      },
      "source": [
        "x.values[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello i am interested'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIu2_PHjYaSS"
      },
      "source": [
        "pip install streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLrvgMkMDgkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce26ab74-4597-43aa-e359-9bd47ced9ac8"
      },
      "source": [
        "import streamlit as st\r\n",
        "import pickle\r\n",
        "import re\r\n",
        "from nltk.corpus import stopwords\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "BOW = pickle.load(open('count_vec.pkl', 'rb'))\r\n",
        "RF=pickle.load(open('Random_Forest_Classifier.pkl','rb'))\r\n",
        "tfidf=pickle.load(open('tfidf_Transformer.pkl','rb'))\r\n",
        "\r\n",
        "\r\n",
        "#tockenization and removing punctutations\r\n",
        "def message_text_process(data):\r\n",
        "  no_punctuation = [char for char in data if char]\r\n",
        "  no_punctuation = \"\".join(no_punctuation)\r\n",
        "  return [word for word in no_punctuation.split() if word.lower()\r\n",
        "          not in stopwords.words(\"english\")]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#data cleaning\r\n",
        "def string_cleaning(data):\r\n",
        "    \r\n",
        "    pattern = r\"\\d*\\/\\d*\\/[a-zA-z]*:|\\d*\\/\\d*\\/\\d*\\(\\w*\\):|\\d*\\|\\w*\\|\\w*:|\\(\\w*\\):|\\d*\\-\\d*\\-\\d*\\(\\w*\\):|\\d*\\/\\d*\\w*:|\\d*\\/\\w*:|\\d*\\/\\d*\\/\\w*\\|:|\\d*\\/\\d*\\ *\\(\\w*\\)|\\d*\\ *\\w*\\ *\\|\\ *\\w*\\ *:|\\d*\\/\\d*\\/\\d*\\(\\w*:|\\d*\\/\\w*\\/\\w*|\\d*\\/\\d*\\/\\d*\\|\\(\\w*\\)|\\(\\w*\\)|\\d*\\-\\d*\\-\\d*|^\\ *|^\\:\"        \r\n",
        "    \r\n",
        "    data = re.sub(pattern,\" \",data)\r\n",
        "    \r\n",
        "    return data\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Random Forest Classifier\r\n",
        "def predict_(data):\r\n",
        "    \r\n",
        "    prediction = RF.predict(data)\r\n",
        "    \r\n",
        "    return prediction\r\n",
        "    \r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def main():\r\n",
        "    \r\n",
        "    \r\n",
        "        st.title(\"Customer Relationship Management\")\r\n",
        "        \r\n",
        "        # phone_number = st.text_input('Customer Phone number with country code!(which is also Unique Id)')\r\n",
        "    \r\n",
        "        # cities = {'hyderabad':16,'pune':35,'mumbai':27, 'delhi':8,'bangalore':3,'australia':2,\r\n",
        "        #        'nagpur':29,'madurai':25,'mysore':28,'kerala':21,'chennai':6,'jalandhar':19,\r\n",
        "        #        'tiruttani':40,'usa':42,'faridabad':9,'online':34,'gurgoan':14,'kochi':23,\r\n",
        "        #        'noida':32,'ahmedabad':0,'khammam':22,'vishakapatnam':44,'solapur':38,\r\n",
        "        #        'nasik':30,'thane':39,'uae':41,'aurangabad':1,'rayagada':37,'bilgi':5,\r\n",
        "        #        'gurgaon':13,'rajamundry':36,'kadapa':20,'vijayawada':43,'kolkatta':24,\r\n",
        "        #        'meerut':26,'jaipur':18,'coimbatore':7,'gujarat':11,'ghazibad':10,'india':17,\r\n",
        "        #        'ongole':33,'nepal':31,'guntur':12,'hubli':15,'bihar':4}\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        # Location = st.selectbox(\"Select a Location from the drop Down meanu\", list(cities.keys()))\r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        \r\n",
        "        if st.button(\"input text box\"):\r\n",
        "            \r\n",
        "            message = st.text_input(\"Customer Response\")\r\n",
        "            \r\n",
        "            data =[message]\r\n",
        "            \r\n",
        "            data = string_cleaning(data)\r\n",
        "            \r\n",
        "            data = data.apply(message_text_process).astype(str)       \r\n",
        "            \r\n",
        "            data = BOW.transform(data)\r\n",
        "        \r\n",
        "            data = tfidf.transform(data)\r\n",
        "            \r\n",
        "            \r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "        if st.button(\"Predict\"):\r\n",
        "            \r\n",
        "            result=predict_(data)\r\n",
        "            \r\n",
        "            if result == ['not converted']:\r\n",
        "                st.success(\"This lead will not going get converted probabily\")\r\n",
        "                \r\n",
        "            else:\r\n",
        "                \r\n",
        "                st.successs(\"This lead will probabily going to get converted! Wish you luck!\")\r\n",
        "            \r\n",
        "            \r\n",
        "        if st.button(\"About\"):\r\n",
        "            st.text(\"Lets Learn\")\r\n",
        "            st.text(\"Built with Streamlit\")\r\n",
        "            \r\n",
        "    \r\n",
        "            \r\n",
        "            \r\n",
        "            \r\n",
        "            \r\n",
        "            \r\n",
        "            \r\n",
        "            \r\n",
        "\r\n",
        "\r\n",
        "if __name__=='__main__':\r\n",
        "        \r\n",
        "            \r\n",
        "        main()\r\n",
        "        \r\n",
        "        #message_text_process(data)\r\n",
        "        "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "2021-02-11 14:01:14.169 WARNING root: \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxRKaCoYZ7Fz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}